#!/opt/SD/env/bin/python3

"""
ReadDocs.py - Szybki odczyt danych z Google Sheets z por√≥wnaniem z bazƒÖ PostgreSQL
Optymalizowany pod kƒÖtem minimalnego czasu odczytu dla zachowania integralno≈õci danych
"""

import pandas as pd
from google.oauth2.service_account import Credentials
import gspread
import psycopg2
from psycopg2.extras import RealDictCursor
from typing import Tuple, List, Dict, Any
import time
import os
import logging
from logging.handlers import RotatingFileHandler
from datetime import datetime
import re

from ConfReadDocs import SCOPES, FILE_KEY, CREDENTIALS_FILE, SHEETS_TO_READ, REQUIRED_COLUMNS, \
    DATA_START_ROW, DB_CONFIG
from db_set import db_insert


# =============================================================================
# KONFIGURACJA LOGOWANIA
# =============================================================================

def setup_logging():
    """
    Konfiguruje system logowania TYLKO do pliku ReadDocs.log z rotacjƒÖ (max 5MB)
    """
    # Pobierz katalog w kt√≥rym znajduje siƒô skrypt
    script_dir = os.path.dirname(os.path.abspath(__file__))
    log_file = os.path.join(script_dir, 'ReadDocs.log')

    # Usu≈Ñ wszystkie istniejƒÖce handlery
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)

    # Konfiguracja RotatingFileHandler z maksymalnym rozmiarem 5MB
    rotating_handler = RotatingFileHandler(
        log_file,
        maxBytes=5 * 1024 * 1024,  # 5MB
        backupCount=3,  # Zachowaj 3 stare pliki (ReadDocs.log.1, ReadDocs.log.2, ReadDocs.log.3)
        encoding='utf-8'
    )

    # Konfiguracja loggera - TYLKO plik, bez konsoli
    logging.basicConfig(
        level=logging.INFO,
        format='%(message)s',
        handlers=[rotating_handler]
    )

    return logging.getLogger(__name__)


def log_session_start(logger):
    """
    Zapisuje nag≈Ç√≥wek sesji w logu
    """
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    separator = "=" * 80

    logger.info(f"\n{separator}")
    logger.info(f"NOWA SESJA READOCS - {timestamp}")
    logger.info(f"PID: {os.getpid()}")
    logger.info(separator)


def log_session_end(logger, success: bool, start_time: float):
    """
    Zapisuje podsumowanie sesji w logu
    """
    end_time = time.time()
    duration = end_time - start_time
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    status = "SUKCES" if success else "B≈ÅƒÑD"
    logger.info(f"\nZAKO≈ÉCZENIE SESJI - {timestamp}")
    logger.info(f"Status: {status}")
    logger.info(f"Czas wykonania: {duration:.2f} sekund")
    logger.info("=" * 80)


# =============================================================================
# G≈Å√ìWNA FUNKCJA ODCZYTU GOOGLE SHEETS
# =============================================================================

def ReadGdocs(file_key: str, credentials_file: str, sheets_dict: Dict[str, int],
              required_columns: Dict[int, str], data_start_row: int, logger) -> Tuple[Dict[int, pd.DataFrame], bool]:
    """
    Funkcja do szybkiego odczytu danych z arkuszy Google Sheets.
    Zoptymalizowana pod kƒÖtem minimalnego czasu wykonania.

    Args:
        file_key (str): Klucz pliku Google Sheets
        credentials_file (str): ≈öcie≈ºka do pliku credentials JSON
        sheets_dict (Dict[str, int]): S≈Çownik mapujƒÖcy nazwy arkuszy na lata
        required_columns (Dict[int, str]): S≈Çownik mapujƒÖcy numery kolumn na nazwy
        data_start_row (int): Numer wiersza od kt√≥rego zaczynajƒÖ siƒô dane (indeks od 0)
        logger: Logger do zapisywania komunikat√≥w

    Returns:
        Tuple[Dict[int, pd.DataFrame], bool]: S≈Çownik DataFrames per rok i status powodzenia operacji
    """

    start_time = time.time()
    tables_by_year = {}
    success = True

    try:
        logger.info(f"üîó ≈ÅƒÖczenie z Google Sheets...")

        # Szybka autoryzacja
        creds = Credentials.from_service_account_file(credentials_file, scopes=SCOPES)
        client = gspread.authorize(creds)

        # Otw√≥rz dokument raz dla wszystkich arkuszy
        spreadsheet = client.open_by_key(file_key)

        logger.info(f"üìä Odczytywanie {len(sheets_dict)} arkuszy...")

        for sheet_name, year in sheets_dict.items():
            try:
                logger.info(f"   üìã Przetwarzanie arkusza: {sheet_name} (rok {year})")

                # Pobierz arkusz
                worksheet = spreadsheet.worksheet(sheet_name)

                # Szybki odczyt wszystkich danych jednym zapytaniem
                all_values = worksheet.get_all_values()

                if len(all_values) <= data_start_row:
                    logger.info(f"   ‚ö†Ô∏è  Arkusz '{sheet_name}' ma za ma≈Ço wierszy!")
                    tables_by_year[year] = pd.DataFrame()
                    continue

                # Wyodrƒôbnij tylko potrzebne kolumny i wiersze
                data_rows = []
                for row_idx in range(data_start_row, len(all_values)):
                    row = all_values[row_idx]
                    # Pobierz tylko wymagane kolumny
                    filtered_row = []
                    for col_idx in sorted(required_columns.keys()):
                        if col_idx < len(row):
                            filtered_row.append(row[col_idx])
                        else:
                            filtered_row.append('')  # Pusta warto≈õƒá je≈õli kolumna nie istnieje
                    data_rows.append(filtered_row)

                # Utw√≥rz DataFrame z odpowiednimi nag≈Ç√≥wkami
                column_names = [required_columns[i] for i in sorted(required_columns.keys())]
                df = pd.DataFrame(data_rows, columns=column_names)

                # Usu≈Ñ ca≈Çkowicie puste wiersze
                df = df.dropna(how='all')

                # Usu≈Ñ wiersze gdzie 'Nr zlecenia' jest pusty (kluczowa kolumna)
                df = df[df['Nr zlecenia'].str.strip() != '']

                tables_by_year[year] = df
                logger.info(f"   ‚úÖ Arkusz '{sheet_name}': {len(df)} wierszy odczytanych")

            except gspread.exceptions.WorksheetNotFound:
                logger.info(f"   ‚ùå Nie znaleziono arkusza: {sheet_name}")
                tables_by_year[year] = pd.DataFrame()
                success = False

            except Exception as e:
                logger.info(f"   ‚ùå B≈ÇƒÖd odczytu arkusza '{sheet_name}': {str(e)}")
                tables_by_year[year] = pd.DataFrame()
                success = False

        elapsed_time = time.time() - start_time
        logger.info(f"‚è±Ô∏è  Ca≈Çkowity czas odczytu: {elapsed_time:.2f} sekund")

        return tables_by_year, success

    except FileNotFoundError:
        logger.info(f"‚ùå Nie znaleziono pliku credentials: {credentials_file}")
        return {}, False

    except Exception as e:
        logger.info(f"‚ùå B≈ÇƒÖd krytyczny: {str(e)}")
        return {}, False


# =============================================================================
# FUNKCJE BAZY DANYCH
# =============================================================================

def get_orders_from_db(year: int, db_config: Dict[str, Any], logger) -> pd.DataFrame:
    """
    Pobiera zam√≥wienia z bazy danych PostgreSQL dla okre≈õlonego roku.

    Args:
        year (int): Rok do filtrowania
        db_config (Dict[str, Any]): Konfiguracja po≈ÇƒÖczenia z bazƒÖ danych
        logger: Logger do zapisywania komunikat√≥w

    Returns:
        pd.DataFrame: DataFrame z danymi z bazy danych
    """

    try:
        # Po≈ÇƒÖczenie z bazƒÖ danych
        conn = psycopg2.connect(**db_config)

        # SQL Query
        query = """
        SELECT id, rokk, rok, nazwa, klient, targi, stoisko, opis, mcs, rks, pm, pow_stoisko, pow_pietra 
        FROM public."ORDERS_nrsde" 
        WHERE rokk = %s;
        """

        # Wykonaj zapytanie i zwr√≥ƒá DataFrame
        df = pd.read_sql_query(query, conn, params=[year])

        conn.close()
        return df

    except Exception as e:
        logger.info(f"‚ùå B≈ÇƒÖd odczytu z bazy danych dla roku {year}: {str(e)}")
        return pd.DataFrame()


def extract_stoisko_from_nazwa(nazwa_stoiska: str) -> str:
    """
    Wyodrƒôbnia czƒô≈õƒá pomiƒôdzy znakami '/' z 'Nazwa STOISKA'.

    Args:
        nazwa_stoiska (str): Pe≈Çna nazwa stoiska

    Returns:
        str: Czƒô≈õƒá pomiƒôdzy znakami '/' lub pusta je≈õli nie znaleziono
    """
    if not nazwa_stoiska or not isinstance(nazwa_stoiska, str):
        return ''

    # Szukaj wzorca pomiƒôdzy znakami '/'
    match = re.search(r'/([^/]+)/', nazwa_stoiska)
    if match:
        return match.group(1).strip()

    # Je≈õli nie ma wzorca z '/', spr√≥buj znale≈∫ƒá pojedynczy znak '/'
    parts = nazwa_stoiska.split('/')
    if len(parts) >= 2:
        # Zwr√≥ƒá czƒô≈õƒá po pierwszym '/' lub przed ostatnim '/'
        return parts[1].strip() if len(parts) == 2 else parts[-2].strip()

    return ''


def prepare_new_record_for_db(google_row: pd.Series, year: int) -> Dict[str, Any]:
    """
    Przygotowuje nowy rekord z Google Sheets do zapisu w bazie danych zgodnie z mapowaniem.

    Args:
        google_row (pd.Series): Wiersz danych z Google Sheets
        year (int): Rok dla kt√≥rego przygotowywany jest rekord

    Returns:
        Dict[str, Any]: S≈Çownik z danymi gotowymi do wstawienia do bazy
    """

    # Dok≈Çadne mapowanie zgodnie z wymaganiami
    new_record = {
        # Rok - z parametru
        'rokk': year,
        'rok': str(year),

        # Mapowanie kolumn Google Sheets -> PostgreSQL
        'nazwa': google_row.get('Nr zlecenia', '').strip(),
        'klient': google_row.get('Nazwa Klienta/Agencja', '').strip(),
        'targi': google_row.get('Nazwa Targ√≥w', '').strip(),
        'opis': google_row.get('Nazwa STOISKA', '').strip(),  # Pe≈Çna nazwa stoiska do opis
        'stoisko': extract_stoisko_from_nazwa(google_row.get('Nazwa STOISKA', '')),  # Czƒô≈õƒá pomiƒôdzy '/'
        'pm': google_row.get('Project Manager', '').strip(),
        'pow_stoisko': google_row.get('Powierzchnia stoiska', '').strip(),
        'pow_pietra': google_row.get('Powierzchnia piƒôtra', '').strip(),

        # Pozosta≈Çe pola - warto≈õci domy≈õlne
        'mcs': None,
        'rks': None
    }

    # Konwersja powierzchni na liczby (je≈õli mo≈ºliwe)
    try:
        if new_record['pow_stoisko']:
            # Zamie≈Ñ przecinek na kropkƒô i usu≈Ñ bia≈Çe znaki
            pow_stoisko_clean = str(new_record['pow_stoisko']).replace(',', '.').strip()
            if pow_stoisko_clean:
                new_record['pow_stoisko'] = float(pow_stoisko_clean)
            else:
                new_record['pow_stoisko'] = None
        else:
            new_record['pow_stoisko'] = None

        if new_record['pow_pietra']:
            # Zamie≈Ñ przecinek na kropkƒô i usu≈Ñ bia≈Çe znaki
            pow_pietra_clean = str(new_record['pow_pietra']).replace(',', '.').strip()
            if pow_pietra_clean:
                new_record['pow_pietra'] = float(pow_pietra_clean)
            else:
                new_record['pow_pietra'] = None
        else:
            new_record['pow_pietra'] = None

    except (ValueError, AttributeError):
        # Je≈õli konwersja siƒô nie uda, zostaw jako None
        new_record['pow_stoisko'] = None
        new_record['pow_pietra'] = None

    return new_record


# Usu≈Ñ zbƒôdne funkcje diagnostyczne
def get_table_structure(db_config: Dict[str, Any], logger) -> Dict[str, str]:
    """
    FUNKCJA USUNIƒòTA - nie jest ju≈º potrzebna przy u≈ºyciu ORM
    """
    pass


def insert_new_records_to_db(new_records: List[Dict[str, Any]], db_config: Dict[str, Any], logger) -> bool:
    """
    Wstawia nowe rekordy do bazy danych u≈ºywajƒÖc funkcji db_insert z db_set.py.

    Args:
        new_records (List[Dict[str, Any]]): Lista nowych rekord√≥w do wstawienia
        db_config (Dict[str, Any]): Konfiguracja po≈ÇƒÖczenia z bazƒÖ danych (nie u≈ºywana)
        logger: Logger do zapisywania komunikat√≥w

    Returns:
        bool: True je≈õli operacja siƒô powiod≈Ça, False w przeciwnym razie
    """

    if not new_records:
        logger.info("üìù Brak nowych rekord√≥w do wstawienia")
        return True

    logger.info(f"üíæ Przygotowanie do wstawienia {len(new_records)} nowych rekord√≥w...")

    inserted_count = 0
    for record in new_records:
        try:
            # Konwersja typ√≥w dla db_insert
            rokk = int(record.get('rokk', 2025))
            rok = int(record.get('rok', 2025))
            nazwa = str(record.get('nazwa', ''))
            klient = str(record.get('klient', ''))
            targi = str(record.get('targi', ''))
            stoisko = str(record.get('stoisko', ''))
            opis = str(record.get('opis', ''))
            pm = str(record.get('pm', ''))

            # Konwersja powierzchni na int
            pow_stoisko = record.get('pow_stoisko', 0)
            if pow_stoisko:
                pow_stoisko = int(float(str(pow_stoisko).replace(',', '.')))
            else:
                pow_stoisko = 0

            pow_pietra = record.get('pow_pietra', 0)
            if pow_pietra:
                pow_pietra = int(float(str(pow_pietra).replace(',', '.')))
            else:
                pow_pietra = 0

            # WYWO≈ÅANIE FUNKCJI Z BIBLIOTEKI db_set.py
            db_insert(rokk, rok, nazwa, klient, targi, stoisko, opis, pm, pow_stoisko, pow_pietra)

            inserted_count += 1
            logger.info(f"   ‚úÖ Wstawiono rekord: {nazwa} | Stoisko: {stoisko} | Klient: {klient}")

        except Exception as e:
            logger.info(f"   ‚ùå B≈ÇƒÖd wstawienia rekordu {record.get('nazwa', 'UNKNOWN')}: {str(e)}")
            continue

    logger.info(f"üíæ Pomy≈õlnie wstawiono {inserted_count} z {len(new_records)} rekord√≥w")
    return inserted_count > 0


def compare_tables(google_df: pd.DataFrame, db_df: pd.DataFrame, year: int, logger) -> List[Dict[str, Any]]:
    """
    Por√≥wnuje tabele z Google Sheets i bazy danych pod wzglƒôdem kolumny 'Nr zlecenia' vs 'nazwa'.
    Zwraca listƒô nowych rekord√≥w gotowych do wstawienia do bazy.

    Args:
        google_df (pd.DataFrame): DataFrame z Google Sheets
        db_df (pd.DataFrame): DataFrame z bazy danych
        year (int): Rok dla kt√≥rego wykonywane jest por√≥wnanie
        logger: Logger do zapisywania komunikat√≥w

    Returns:
        List[Dict[str, Any]]: Lista nowych rekord√≥w do wstawienia do bazy
    """

    new_records_for_db = []

    if google_df.empty and db_df.empty:
        logger.info(f"‚úÖ ROK {year}: Tabele sƒÖ r√≥wne - obie puste")
        return new_records_for_db

    if google_df.empty:
        logger.info(f"‚ö†Ô∏è  ROK {year}: Google Sheets pusty, baza danych ma {len(db_df)} rekord√≥w")
        return new_records_for_db

    if db_df.empty:
        logger.info(f"‚ö†Ô∏è  ROK {year}: Baza danych pusta, Google Sheets ma {len(google_df)} rekord√≥w")
        # Przygotuj wszystkie wiersze z Google Sheets do wstawienia
        for _, row in google_df.iterrows():
            row_dict = row.to_dict()
            logger.info(f"   NOWY: {row_dict}")

            # Przygotuj rekord do wstawienia do bazy
            db_record = prepare_new_record_for_db(row, year)
            new_records_for_db.append(db_record)

        return new_records_for_db

    # Pobierz warto≈õci z kolumn por√≥wnania (czy≈õƒá bia≈Çe znaki)
    google_orders = set(google_df['Nr zlecenia'].astype(str).str.strip())
    db_orders = set(db_df['nazwa'].astype(str).str.strip())

    # Usu≈Ñ puste warto≈õci
    google_orders.discard('')
    db_orders.discard('')

    # Znajd≈∫ r√≥≈ºnice
    new_in_google = google_orders - db_orders

    if not new_in_google:
        logger.info(f"‚úÖ ROK {year}: Tabele sƒÖ r√≥wne - {len(google_orders)} identycznych rekord√≥w")
    else:
        logger.info(f"üìà ROK {year}: Znaleziono {len(new_in_google)} nowych rekord√≥w w Google Sheets:")

        # Wy≈õwietl pe≈Çne wiersze dla nowych rekord√≥w i przygotuj do wstawienia
        for order_nr in new_in_google:
            matching_rows = google_df[google_df['Nr zlecenia'].astype(str).str.strip() == order_nr]
            for _, row in matching_rows.iterrows():
                row_dict = row.to_dict()
                logger.info(f"   NOWY: {row_dict}")

                # Przygotuj rekord do wstawienia do bazy
                db_record = prepare_new_record_for_db(row, year)
                new_records_for_db.append(db_record)

    return new_records_for_db


# =============================================================================
# G≈Å√ìWNA FUNKCJA PROGRAMU
# =============================================================================

def main():
    """
    G≈Ç√≥wna funkcja programu
    """
    # Zapisz czas rozpoczƒôcia sesji
    session_start_time = time.time()

    # Skonfiguruj logowanie
    logger = setup_logging()

    # Zaloguj rozpoczƒôcie sesji
    log_session_start(logger)

    logger.info("üöÄ POR√ìWNANIE DANYCH GOOGLE SHEETS Z BAZƒÑ POSTGRESQL")
    logger.info("=" * 65)

    # Wywo≈Çaj g≈Ç√≥wnƒÖ funkcjƒô odczytu Google Sheets
    google_tables, google_success = ReadGdocs(
        file_key=FILE_KEY,
        credentials_file=CREDENTIALS_FILE,
        sheets_dict=SHEETS_TO_READ,
        required_columns=REQUIRED_COLUMNS,
        data_start_row=DATA_START_ROW,
        logger=logger
    )

    if not google_success:
        logger.info("‚ùå B≈ÇƒÖd odczytu Google Sheets - przerywanie")
        log_session_end(logger, False, session_start_time)
        return False

    logger.info("\nüóÉÔ∏è  Pobieranie danych z bazy PostgreSQL i por√≥wnanie...")

    all_new_records = []

    # Dla ka≈ºdego roku pobierz dane z bazy i por√≥wnaj
    for year in SHEETS_TO_READ.values():
        db_df = get_orders_from_db(year, DB_CONFIG, logger)
        google_df = google_tables.get(year, pd.DataFrame())

        # Por√≥wnaj tabele i zbierz nowe rekordy
        new_records = compare_tables(google_df, db_df, year, logger)
        all_new_records.extend(new_records)

    # Wstaw nowe rekordy do bazy danych - NOWA METODA
    if all_new_records:
        logger.info(f"\nüíæ Rozpoczƒôcie wstawiania {len(all_new_records)} nowych rekord√≥w do bazy...")
        insert_success = insert_new_records_to_db(all_new_records, DB_CONFIG, logger)

    logger.info(f"\nüìä PODSUMOWANIE: Znaleziono {len(all_new_records)} nowych rekord√≥w gotowych do wstawienia")

    # Zaloguj zako≈Ñczenie sesji
    log_session_end(logger, True, session_start_time)
    return True


# =============================================================================
# URUCHOMIENIE SKRYPTU
# =============================================================================

if __name__ == "__main__":
    success = main()

    if success:
        exit(0)
    else:
        exit(1)







































# #!/opt/PROJEKTY/SDA/env/bin/python3
#
# """
# ReadDocs.py - Szybki odczyt danych z Google Sheets z por√≥wnaniem z bazƒÖ PostgreSQL
# Optymalizowany pod kƒÖtem minimalnego czasu odczytu dla zachowania integralno≈õci danych
# """
#
# import pandas as pd
# from google.oauth2.service_account import Credentials
# import gspread
# import psycopg2
# from psycopg2.extras import RealDictCursor
# from typing import Tuple, List, Dict, Any
# import time
# import os
# import logging
# from logging.handlers import RotatingFileHandler
# from datetime import datetime
# import re
#
# from ConfReadDocs import SCOPES, FILE_KEY, CREDENTIALS_FILE, SHEETS_TO_READ, REQUIRED_COLUMNS, \
#     DATA_START_ROW, DB_CONFIG
# from db_set import db_insert
#
#
# # =============================================================================
# # KONFIGURACJA LOGOWANIA
# # =============================================================================
#
# def setup_logging():
#     """
#     Konfiguruje system logowania TYLKO do pliku ReadDocs.log z rotacjƒÖ (max 5MB)
#     """
#     # Pobierz katalog w kt√≥rym znajduje siƒô skrypt
#     script_dir = os.path.dirname(os.path.abspath(__file__))
#     log_file = os.path.join(script_dir, 'ReadDocs.log')
#
#     # Usu≈Ñ wszystkie istniejƒÖce handlery
#     for handler in logging.root.handlers[:]:
#         logging.root.removeHandler(handler)
#
#     # Konfiguracja RotatingFileHandler z maksymalnym rozmiarem 5MB
#     rotating_handler = RotatingFileHandler(
#         log_file,
#         maxBytes=5 * 1024 * 1024,  # 5MB
#         backupCount=3,  # Zachowaj 3 stare pliki (ReadDocs.log.1, ReadDocs.log.2, ReadDocs.log.3)
#         encoding='utf-8'
#     )
#
#     # Konfiguracja loggera - TYLKO plik, bez konsoli
#     logging.basicConfig(
#         level=logging.INFO,
#         format='%(message)s',
#         handlers=[rotating_handler]
#     )
#
#     return logging.getLogger(__name__)
#
#
# def log_session_start(logger):
#     """
#     Zapisuje nag≈Ç√≥wek sesji w logu
#     """
#     timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
#     separator = "=" * 80
#
#     logger.info(f"\n{separator}")
#     logger.info(f"NOWA SESJA READOCS - {timestamp}")
#     logger.info(f"PID: {os.getpid()}")
#     logger.info(separator)
#
#
# def log_session_end(logger, success: bool, start_time: float):
#     """
#     Zapisuje podsumowanie sesji w logu
#     """
#     end_time = time.time()
#     duration = end_time - start_time
#     timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
#
#     status = "SUKCES" if success else "B≈ÅƒÑD"
#     logger.info(f"\nZAKO≈ÉCZENIE SESJI - {timestamp}")
#     logger.info(f"Status: {status}")
#     logger.info(f"Czas wykonania: {duration:.2f} sekund")
#     logger.info("=" * 80)
#
#
# # =============================================================================
# # G≈Å√ìWNA FUNKCJA ODCZYTU GOOGLE SHEETS
# # =============================================================================
#
# def ReadGdocs(file_key: str, credentials_file: str, sheets_dict: Dict[str, int],
#               required_columns: Dict[int, str], data_start_row: int, logger) -> Tuple[Dict[int, pd.DataFrame], bool]:
#     """
#     Funkcja do szybkiego odczytu danych z arkuszy Google Sheets.
#     Zoptymalizowana pod kƒÖtem minimalnego czasu wykonania.
#
#     Args:
#         file_key (str): Klucz pliku Google Sheets
#         credentials_file (str): ≈öcie≈ºka do pliku credentials JSON
#         sheets_dict (Dict[str, int]): S≈Çownik mapujƒÖcy nazwy arkuszy na lata
#         required_columns (Dict[int, str]): S≈Çownik mapujƒÖcy numery kolumn na nazwy
#         data_start_row (int): Numer wiersza od kt√≥rego zaczynajƒÖ siƒô dane (indeks od 0)
#         logger: Logger do zapisywania komunikat√≥w
#
#     Returns:
#         Tuple[Dict[int, pd.DataFrame], bool]: S≈Çownik DataFrames per rok i status powodzenia operacji
#     """
#
#     start_time = time.time()
#     tables_by_year = {}
#     success = True
#
#     try:
#         logger.info(f"üîó ≈ÅƒÖczenie z Google Sheets...")
#
#         # Szybka autoryzacja
#         creds = Credentials.from_service_account_file(credentials_file, scopes=SCOPES)
#         client = gspread.authorize(creds)
#
#         # Otw√≥rz dokument raz dla wszystkich arkuszy
#         spreadsheet = client.open_by_key(file_key)
#
#         logger.info(f"üìä Odczytywanie {len(sheets_dict)} arkuszy...")
#
#         for sheet_name, year in sheets_dict.items():
#             try:
#                 logger.info(f"   üìã Przetwarzanie arkusza: {sheet_name} (rok {year})")
#
#                 # Pobierz arkusz
#                 worksheet = spreadsheet.worksheet(sheet_name)
#
#                 # Szybki odczyt wszystkich danych jednym zapytaniem
#                 all_values = worksheet.get_all_values()
#
#                 if len(all_values) <= data_start_row:
#                     logger.info(f"   ‚ö†Ô∏è  Arkusz '{sheet_name}' ma za ma≈Ço wierszy!")
#                     tables_by_year[year] = pd.DataFrame()
#                     continue
#
#                 # Wyodrƒôbnij tylko potrzebne kolumny i wiersze
#                 data_rows = []
#                 for row_idx in range(data_start_row, len(all_values)):
#                     row = all_values[row_idx]
#                     # Pobierz tylko wymagane kolumny
#                     filtered_row = []
#                     for col_idx in sorted(required_columns.keys()):
#                         if col_idx < len(row):
#                             filtered_row.append(row[col_idx])
#                         else:
#                             filtered_row.append('')  # Pusta warto≈õƒá je≈õli kolumna nie istnieje
#                     data_rows.append(filtered_row)
#
#                 # Utw√≥rz DataFrame z odpowiednimi nag≈Ç√≥wkami
#                 column_names = [required_columns[i] for i in sorted(required_columns.keys())]
#                 df = pd.DataFrame(data_rows, columns=column_names)
#
#                 # Usu≈Ñ ca≈Çkowicie puste wiersze
#                 df = df.dropna(how='all')
#
#                 # Usu≈Ñ wiersze gdzie 'Nr zlecenia' jest pusty (kluczowa kolumna)
#                 df = df[df['Nr zlecenia'].str.strip() != '']
#
#                 tables_by_year[year] = df
#                 logger.info(f"   ‚úÖ Arkusz '{sheet_name}': {len(df)} wierszy odczytanych")
#
#             except gspread.exceptions.WorksheetNotFound:
#                 logger.info(f"   ‚ùå Nie znaleziono arkusza: {sheet_name}")
#                 tables_by_year[year] = pd.DataFrame()
#                 success = False
#
#             except Exception as e:
#                 logger.info(f"   ‚ùå B≈ÇƒÖd odczytu arkusza '{sheet_name}': {str(e)}")
#                 tables_by_year[year] = pd.DataFrame()
#                 success = False
#
#         elapsed_time = time.time() - start_time
#         logger.info(f"‚è±Ô∏è  Ca≈Çkowity czas odczytu: {elapsed_time:.2f} sekund")
#
#         return tables_by_year, success
#
#     except FileNotFoundError:
#         logger.info(f"‚ùå Nie znaleziono pliku credentials: {credentials_file}")
#         return {}, False
#
#     except Exception as e:
#         logger.info(f"‚ùå B≈ÇƒÖd krytyczny: {str(e)}")
#         return {}, False
#
#
# # =============================================================================
# # FUNKCJE BAZY DANYCH
# # =============================================================================
#
# def get_orders_from_db(year: int, db_config: Dict[str, Any], logger) -> pd.DataFrame:
#     """
#     Pobiera zam√≥wienia z bazy danych PostgreSQL dla okre≈õlonego roku.
#
#     Args:
#         year (int): Rok do filtrowania
#         db_config (Dict[str, Any]): Konfiguracja po≈ÇƒÖczenia z bazƒÖ danych
#         logger: Logger do zapisywania komunikat√≥w
#
#     Returns:
#         pd.DataFrame: DataFrame z danymi z bazy danych
#     """
#
#     try:
#         # Po≈ÇƒÖczenie z bazƒÖ danych
#         conn = psycopg2.connect(**db_config)
#
#         # SQL Query
#         query = """
#         SELECT id, rokk, rok, nazwa, klient, targi, stoisko, opis, mcs, rks, pm, pow_stoisko, pow_pietra
#         FROM public."ORDERS_nrsde"
#         WHERE rokk = %s;
#         """
#
#         # Wykonaj zapytanie i zwr√≥ƒá DataFrame
#         df = pd.read_sql_query(query, conn, params=[year])
#
#         conn.close()
#         return df
#
#     except Exception as e:
#         logger.info(f"‚ùå B≈ÇƒÖd odczytu z bazy danych dla roku {year}: {str(e)}")
#         return pd.DataFrame()
#
#
# def extract_stoisko_from_nazwa(nazwa_stoiska: str) -> str:
#     """
#     Wyodrƒôbnia czƒô≈õƒá pomiƒôdzy znakami '/' z 'Nazwa STOISKA'.
#
#     Args:
#         nazwa_stoiska (str): Pe≈Çna nazwa stoiska
#
#     Returns:
#         str: Czƒô≈õƒá pomiƒôdzy znakami '/' lub pusta je≈õli nie znaleziono
#     """
#     if not nazwa_stoiska or not isinstance(nazwa_stoiska, str):
#         return ''
#
#     # Szukaj wzorca pomiƒôdzy znakami '/'
#     match = re.search(r'/([^/]+)/', nazwa_stoiska)
#     if match:
#         return match.group(1).strip()
#
#     # Je≈õli nie ma wzorca z '/', spr√≥buj znale≈∫ƒá pojedynczy znak '/'
#     parts = nazwa_stoiska.split('/')
#     if len(parts) >= 2:
#         # Zwr√≥ƒá czƒô≈õƒá po pierwszym '/' lub przed ostatnim '/'
#         return parts[1].strip() if len(parts) == 2 else parts[-2].strip()
#
#     return ''
#
#
# def prepare_new_record_for_db(google_row: pd.Series, year: int) -> Dict[str, Any]:
#     """
#     Przygotowuje nowy rekord z Google Sheets do zapisu w bazie danych zgodnie z mapowaniem.
#
#     Args:
#         google_row (pd.Series): Wiersz danych z Google Sheets
#         year (int): Rok dla kt√≥rego przygotowywany jest rekord
#
#     Returns:
#         Dict[str, Any]: S≈Çownik z danymi gotowymi do wstawienia do bazy
#     """
#
#     # Dok≈Çadne mapowanie zgodnie z wymaganiami
#     new_record = {
#         # Rok - z parametru
#         'rokk': year,
#         'rok': str(year),
#
#         # Mapowanie kolumn Google Sheets -> PostgreSQL
#         'nazwa': google_row.get('Nr zlecenia', '').strip(),
#         'klient': google_row.get('Nazwa Klienta/Agencja', '').strip(),
#         'targi': google_row.get('Nazwa Targ√≥w', '').strip(),
#         'opis': google_row.get('Nazwa STOISKA', '').strip(),  # Pe≈Çna nazwa stoiska do opis
#         'stoisko': extract_stoisko_from_nazwa(google_row.get('Nazwa STOISKA', '')),  # Czƒô≈õƒá pomiƒôdzy '/'
#         'pm': google_row.get('Project Manager', '').strip(),
#         'pow_stoisko': google_row.get('Powierzchnia stoiska', '').strip(),
#         'pow_pietra': google_row.get('Powierzchnia piƒôtra', '').strip(),
#
#         # Pozosta≈Çe pola - warto≈õci domy≈õlne
#         'mcs': None,
#         'rks': None
#     }
#
#     # Konwersja powierzchni na liczby (je≈õli mo≈ºliwe)
#     try:
#         if new_record['pow_stoisko']:
#             # Zamie≈Ñ przecinek na kropkƒô i usu≈Ñ bia≈Çe znaki
#             pow_stoisko_clean = str(new_record['pow_stoisko']).replace(',', '.').strip()
#             if pow_stoisko_clean:
#                 new_record['pow_stoisko'] = float(pow_stoisko_clean)
#             else:
#                 new_record['pow_stoisko'] = None
#         else:
#             new_record['pow_stoisko'] = None
#
#         if new_record['pow_pietra']:
#             # Zamie≈Ñ przecinek na kropkƒô i usu≈Ñ bia≈Çe znaki
#             pow_pietra_clean = str(new_record['pow_pietra']).replace(',', '.').strip()
#             if pow_pietra_clean:
#                 new_record['pow_pietra'] = float(pow_pietra_clean)
#             else:
#                 new_record['pow_pietra'] = None
#         else:
#             new_record['pow_pietra'] = None
#
#     except (ValueError, AttributeError):
#         # Je≈õli konwersja siƒô nie uda, zostaw jako None
#         new_record['pow_stoisko'] = None
#         new_record['pow_pietra'] = None
#
#     return new_record
#
#
# # Usu≈Ñ zbƒôdne funkcje diagnostyczne
# def get_table_structure(db_config: Dict[str, Any], logger) -> Dict[str, str]:
#     """
#     FUNKCJA USUNIƒòTA - nie jest ju≈º potrzebna przy u≈ºyciu ORM
#     """
#     pass
#
#
# def insert_new_records_to_db(new_records: List[Dict[str, Any]], db_config: Dict[str, Any], logger) -> bool:
#     """
#     Wstawia nowe rekordy do bazy danych u≈ºywajƒÖc funkcji db_insert z db_set.py.
#
#     Args:
#         new_records (List[Dict[str, Any]]): Lista nowych rekord√≥w do wstawienia
#         db_config (Dict[str, Any]): Konfiguracja po≈ÇƒÖczenia z bazƒÖ danych (nie u≈ºywana)
#         logger: Logger do zapisywania komunikat√≥w
#
#     Returns:
#         bool: True je≈õli operacja siƒô powiod≈Ça, False w przeciwnym razie
#     """
#
#     if not new_records:
#         logger.info("üìù Brak nowych rekord√≥w do wstawienia")
#         return True
#
#     logger.info(f"üíæ Przygotowanie do wstawienia {len(new_records)} nowych rekord√≥w...")
#
#     inserted_count = 0
#     for record in new_records:
#         print(">>> ", record)
#         try:
#             # Konwersja typ√≥w dla db_insert
#             rokk = int(record.get('rokk', 2025))
#             rok = int(record.get('rok', 2025))
#             nazwa = str(record.get('nazwa', ''))
#             klient = str(record.get('klient', ''))
#             targi = str(record.get('targi', ''))
#             stoisko = str(record.get('stoisko', ''))
#             opis = str(record.get('opis', ''))
#             pm = str(record.get('pm', ''))
#
#             # Konwersja powierzchni na int
#             pow_stoisko = record.get('pow_stoisko', 0)
#             if pow_stoisko:
#                 pow_stoisko = int(float(str(pow_stoisko).replace(',', '.')))
#             else:
#                 pow_stoisko = 0
#
#             pow_pietra = record.get('pow_pietra', 0)
#             if pow_pietra:
#                 pow_pietra = int(float(str(pow_pietra).replace(',', '.')))
#             else:
#                 pow_pietra = 0
#
#             # WYWO≈ÅANIE FUNKCJI Z BIBLIOTEKI db_set.py
#             #db_insert(rokk, rok, nazwa, klient, targi, stoisko, opis, pm, pow_stoisko, pow_pietra)
#
#             inserted_count += 1
#             logger.info(f"   ‚úÖ Wstawiono rekord: {nazwa} | Stoisko: {stoisko} | Klient: {klient}")
#
#         except Exception as e:
#             logger.info(f"   ‚ùå B≈ÇƒÖd wstawienia rekordu {record.get('nazwa', 'UNKNOWN')}: {str(e)}")
#             continue
#
#     logger.info(f"üíæ Pomy≈õlnie wstawiono {inserted_count} z {len(new_records)} rekord√≥w")
#     return inserted_count > 0
#
#
# def compare_tables(google_df: pd.DataFrame, db_df: pd.DataFrame, year: int, logger) -> List[Dict[str, Any]]:
#     """
#     Por√≥wnuje tabele z Google Sheets i bazy danych pod wzglƒôdem kolumny 'Nr zlecenia' vs 'nazwa'.
#     Zwraca listƒô nowych rekord√≥w gotowych do wstawienia do bazy.
#
#     Args:
#         google_df (pd.DataFrame): DataFrame z Google Sheets
#         db_df (pd.DataFrame): DataFrame z bazy danych
#         year (int): Rok dla kt√≥rego wykonywane jest por√≥wnanie
#         logger: Logger do zapisywania komunikat√≥w
#
#     Returns:
#         List[Dict[str, Any]]: Lista nowych rekord√≥w do wstawienia do bazy
#     """
#
#     new_records_for_db = []
#
#     if google_df.empty and db_df.empty:
#         logger.info(f"‚úÖ ROK {year}: Tabele sƒÖ r√≥wne - obie puste")
#         return new_records_for_db
#
#     if google_df.empty:
#         logger.info(f"‚ö†Ô∏è  ROK {year}: Google Sheets pusty, baza danych ma {len(db_df)} rekord√≥w")
#         return new_records_for_db
#
#     if db_df.empty:
#         logger.info(f"‚ö†Ô∏è  ROK {year}: Baza danych pusta, Google Sheets ma {len(google_df)} rekord√≥w")
#         # Przygotuj wszystkie wiersze z Google Sheets do wstawienia
#         for _, row in google_df.iterrows():
#             row_dict = row.to_dict()
#             logger.info(f"   NOWY: {row_dict}")
#
#             # Przygotuj rekord do wstawienia do bazy
#             db_record = prepare_new_record_for_db(row, year)
#             new_records_for_db.append(db_record)
#
#         return new_records_for_db
#
#     # Pobierz warto≈õci z kolumn por√≥wnania (czy≈õƒá bia≈Çe znaki)
#     google_orders = set(google_df['Nr zlecenia'].astype(str).str.strip())
#     db_orders = set(db_df['nazwa'].astype(str).str.strip())
#
#     # Usu≈Ñ puste warto≈õci
#     google_orders.discard('')
#     db_orders.discard('')
#
#     # Znajd≈∫ r√≥≈ºnice
#     new_in_google = google_orders - db_orders
#
#     if not new_in_google:
#         logger.info(f"‚úÖ ROK {year}: Tabele sƒÖ r√≥wne - {len(google_orders)} identycznych rekord√≥w")
#     else:
#         logger.info(f"üìà ROK {year}: Znaleziono {len(new_in_google)} nowych rekord√≥w w Google Sheets:")
#
#         # Wy≈õwietl pe≈Çne wiersze dla nowych rekord√≥w i przygotuj do wstawienia
#         for order_nr in new_in_google:
#             matching_rows = google_df[google_df['Nr zlecenia'].astype(str).str.strip() == order_nr]
#             for _, row in matching_rows.iterrows():
#                 row_dict = row.to_dict()
#                 logger.info(f"   NOWY: {row_dict}")
#
#                 # Przygotuj rekord do wstawienia do bazy
#                 db_record = prepare_new_record_for_db(row, year)
#                 new_records_for_db.append(db_record)
#
#     return new_records_for_db
#
#
# # =============================================================================
# # G≈Å√ìWNA FUNKCJA PROGRAMU
# # =============================================================================
#
# def main():
#     """
#     G≈Ç√≥wna funkcja programu
#     """
#     # Zapisz czas rozpoczƒôcia sesji
#     session_start_time = time.time()
#
#     # Skonfiguruj logowanie
#     logger = setup_logging()
#
#     # Zaloguj rozpoczƒôcie sesji
#     log_session_start(logger)
#
#     logger.info("üöÄ POR√ìWNANIE DANYCH GOOGLE SHEETS Z BAZƒÑ POSTGRESQL")
#     logger.info("=" * 65)
#
#     # Wywo≈Çaj g≈Ç√≥wnƒÖ funkcjƒô odczytu Google Sheets
#     google_tables, google_success = ReadGdocs(
#         file_key=FILE_KEY,
#         credentials_file=CREDENTIALS_FILE,
#         sheets_dict=SHEETS_TO_READ,
#         required_columns=REQUIRED_COLUMNS,
#         data_start_row=DATA_START_ROW,
#         logger=logger
#     )
#
#     if not google_success:
#         logger.info("‚ùå B≈ÇƒÖd odczytu Google Sheets - przerywanie")
#         log_session_end(logger, False, session_start_time)
#         return False
#
#     logger.info("\nüóÉÔ∏è  Pobieranie danych z bazy PostgreSQL i por√≥wnanie...")
#
#     all_new_records = []
#
#     # Dla ka≈ºdego roku pobierz dane z bazy i por√≥wnaj
#     for year in SHEETS_TO_READ.values():
#         db_df = get_orders_from_db(year, DB_CONFIG, logger)
#         google_df = google_tables.get(year, pd.DataFrame())
#
#         # Por√≥wnaj tabele i zbierz nowe rekordy
#         new_records = compare_tables(google_df, db_df, year, logger)
#         all_new_records.extend(new_records)
#
#     # Wstaw nowe rekordy do bazy danych - NOWA METODA
#     if all_new_records:
#         logger.info(f"\nüíæ Rozpoczƒôcie wstawiania {len(all_new_records)} nowych rekord√≥w do bazy...")
#         insert_success = insert_new_records_to_db(all_new_records, DB_CONFIG, logger)
#
#     logger.info(f"\nüìä PODSUMOWANIE: Znaleziono {len(all_new_records)} nowych rekord√≥w gotowych do wstawienia")
#
#     # Zaloguj zako≈Ñczenie sesji
#     log_session_end(logger, True, session_start_time)
#     return True
#
#
# # =============================================================================
# # URUCHOMIENIE SKRYPTU
# # =============================================================================
#
# if __name__ == "__main__":
#     success = main()
#
#     if success:
#         exit(0)
#     else:
#         exit(1)
